# -*- coding: utf-8 -*-
"""Scikit_NN_Perceptron

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xJPPhpGfkn_i4iBSBpfm-Si_93oT2xow
"""

import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.linear_model import Perceptron
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report

iris = load_iris()
X = iris.data[:,(2,3)]

print(X)



y = (iris.target==0).astype(np.int8)

p = Perceptron(tol=0.001)

p.fit(X, y)

for val in X:
  pred = p.predict([val])

import sys
import warnings
warnings.simplefilter('ignore')

print(__doc__)


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.5, random_state=0)

tuned_parameters = [{'tol': [0.01,0.001,0.0001]}]

scores = ['precision', 'recall']


for score in scores:

  print("#Tuning")
  print()
  cv_list = [5,10,15,20,25]
  for cv1 in cv_list:

    clf = GridSearchCV(Perceptron(), tuned_parameters, cv= cv1, scoring='%s_macro' % score)

    clf.fit(X_train, y_train)

    print("Best parameters set found on set:")
    print()
    print(clf.best_params_)
    print()
    print("Grid scores on dev set:")
    print()
    means = clf.cv_results_['mean_test_score']
    stds = clf.cv_results_['std_test_score']

    for mean, std, params in zip(means, stds, clf.cv_results_['params']):
      print("%0.3f (+/-%0.03f) for %r" % (mean, std*2, params))


    print()
    print("Classification report:")



    y_true, y_pred = y_test, clf.predict(X_test)

    print(classification_report(y_true, y_pred))
    print()



from sklearn.neural_network import MLPClassifier

clf = MLPClassifier(activation = "identity",solver='lbfgs', alpha = 1e-5, 
                    hidden_layer_sizes = (5,2,4,12))
clf.fit(X,y)

print("weights between IP layers and 1st hidden layer")
print(clf.coefs_[0])

print("Weights between 1st hidden layer and second hidden layer")
print(clf.coefs_[1])

for i in range(len(clf.coefs_)):
  number_neurons_in_layer = clf.coefs_[i].shape[1]
  for j in range(number_neurons_in_layer):
    weights = clf.coefs_[i][:,j]
    print(i, j, weights, end=", ")
    print()

  print()

import sys
import warnings
warnings.simplefilter('ignore')

print(__doc__)


X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.5, random_state=0)

tuned_parameters = [{'hidden_layer_sizes' : [(100, ), (200, ), (400, ), (500, )],
                     'activation' : ['identity', 'logistic', 'tanh', 'relu'],
                     'solver' : ['lbfgs'],
                     'alpha' : [0.001, 0.0001, 0.00001],
                     'learning_rate' : ['constant', 'invscaling', 'adaptive']}]

scores = ['precision', 'recall']


for score in scores:

  print("#Tuning")
  print()
  cv_list = [5,10,15,20,25]
  for cv1 in cv_list:

    clf = GridSearchCV(MLPClassifier(), tuned_parameters, cv= cv1, scoring='%s_macro' % score)

    clf.fit(X_train, y_train)

    print("Best parameters set found on set:")
    print()
    print(clf.best_params_)
    print()
    print("Grid scores on dev set:")
    print()
    means = clf.cv_results_['mean_test_score']
    stds = clf.cv_results_['std_test_score']

    for mean, std, params in zip(means, stds, clf.cv_results_['params']):
      print("%0.3f (+/-%0.03f) for %r" % (mean, std*2, params))


    print()
    print("Classification report:")



    y_true, y_pred = y_test, clf.predict(X_test)

    print(classification_report(y_true, y_pred))
    print()